from fastapi import FastAPI
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
import cv2
import os
import sys
import numpy as np
import json
import ctypes
import time

try:
    from hobot_dnn import pyeasy_dnn as dnn
except ImportError:
    from hobot_dnn_rdkx5 import pyeasy_dnn as dnn

app = FastAPI()

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ã™ã¹ã¦ã®ã‚ªãƒªã‚¸ãƒ³ã‚’è¨±å¯
    allow_credentials=True,
    allow_methods=["*"],  # ã™ã¹ã¦ã®HTTPãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¨±å¯
    allow_headers=["*"],  # ã™ã¹ã¦ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨±å¯
)

# Classes from coco_classes.names
with open('coco_classes.names', 'r') as f:
    classes = [line.strip() for line in f.readlines()]

# YOLOv5 model path
model_path = '/app/pydev_demo/models/yolov5s_672x672_nv12.bin'  # Adjust path if needed

# Load model
models = dnn.load(model_path)

# Define ctypes structures (from test_yolov5.py)
class hbSysMem_t(ctypes.Structure):
    _fields_ = [
        ("phyAddr", ctypes.c_double),
        ("virAddr", ctypes.c_void_p),
        ("memSize", ctypes.c_int)
    ]

class hbDNNQuantiShift_yt(ctypes.Structure):
    _fields_ = [
        ("shiftLen", ctypes.c_int),
        ("shiftData", ctypes.c_char_p)
    ]

class hbDNNQuantiScale_t(ctypes.Structure):
    _fields_ = [
        ("scaleLen", ctypes.c_int),
        ("scaleData", ctypes.POINTER(ctypes.c_float)),
        ("zeroPointLen", ctypes.c_int),
        ("zeroPointData", ctypes.c_char_p)
    ]

class hbDNNTensorShape_t(ctypes.Structure):
    _fields_ = [
        ("dimensionSize", ctypes.c_int * 8),
        ("numDimensions", ctypes.c_int)
    ]

class hbDNNTensorProperties_t(ctypes.Structure):
    _fields_ = [
        ("validShape", hbDNNTensorShape_t),
        ("alignedShape", hbDNNTensorShape_t),
        ("tensorLayout", ctypes.c_int),
        ("tensorType", ctypes.c_int),
        ("shift", hbDNNQuantiShift_yt),
        ("scale", hbDNNQuantiScale_t),
        ("quantiType", ctypes.c_int),
        ("quantizeAxis", ctypes.c_int),
        ("alignedByteSize", ctypes.c_int),
        ("stride", ctypes.c_int * 8)
    ]

class hbDNNTensor_t(ctypes.Structure):
    _fields_ = [
        ("sysMem", hbSysMem_t * 4),
        ("properties", hbDNNTensorProperties_t)
    ]

class Yolov5PostProcessInfo_t(ctypes.Structure):
    _fields_ = [
        ("height", ctypes.c_int),
        ("width", ctypes.c_int),
        ("ori_height", ctypes.c_int),
        ("ori_width", ctypes.c_int),
        ("score_threshold", ctypes.c_float),
        ("nms_threshold", ctypes.c_float),
        ("nms_top_k", ctypes.c_int),
        ("is_pad_resize", ctypes.c_int)
    ]

libpostprocess = ctypes.CDLL('/usr/lib/libpostprocess.so')

get_Postprocess_result = libpostprocess.Yolov5PostProcess
get_Postprocess_result.argtypes = [ctypes.POINTER(Yolov5PostProcessInfo_t)]
get_Postprocess_result.restype = ctypes.c_char_p

def get_TensorLayout(Layout):
    if Layout == "NCHW":
        return int(2)
    else:
        return int(0)

def bgr2nv12_opencv(image):
    height, width = image.shape[0], image.shape[1]
    area = height * width
    yuv420p = cv2.cvtColor(image, cv2.COLOR_BGR2YUV_I420).reshape((area * 3 // 2,))
    y = yuv420p[:area]
    uv_planar = yuv420p[area:].reshape((2, area // 4))
    uv_packed = uv_planar.transpose((1, 0)).reshape((area // 2,))

    nv12 = np.zeros_like(yuv420p)
    nv12[:height * width] = y
    nv12[height * width:] = uv_packed
    return nv12

def get_hw(pro):
    if pro.layout == "NCHW":
        return pro.shape[2], pro.shape[3]
    else:
        return pro.shape[1], pro.shape[2]

def is_usb_camera(device):
    try:
        cap = cv2.VideoCapture(device)
        if not cap.isOpened():
            return False
        cap.release()
        return True
    except Exception:
        return False

def find_first_usb_camera():
    video_devices = [os.path.join('/dev', dev) for dev in os.listdir('/dev') if dev.startswith('video')]
    for dev in video_devices:
        if is_usb_camera(dev):
            return dev
    return None

def capture_image():
    video_device = find_first_usb_camera()
    if video_device is None:
        raise Exception("No USB camera found.")
    
    cap = cv2.VideoCapture(video_device)
    if not cap.isOpened():
        raise Exception(f"Failed to open video device: {video_device}")
    
    # Set camera properties
    codec = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
    cap.set(cv2.CAP_PROP_FOURCC, codec)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    
    ret, frame = cap.read()
    cap.release()
    if not ret or frame is None:
        raise Exception("Failed to capture image from USB camera")
    return frame

def detect_objects(image):
    """ç‰©ä½“æ¤œå‡ºã‚’å®Ÿè¡Œã—ã€æ¤œå‡ºçµæœã‚’è¿”ã™"""
    h, w = get_hw(models[0].inputs[0].properties)
    des_dim = (w, h)
    resized_data = cv2.resize(image, des_dim, interpolation=cv2.INTER_AREA)
    nv12_data = bgr2nv12_opencv(resized_data)
    
    outputs = models[0].forward(nv12_data)
    
    # Postprocess
    yolov5_postprocess_info = Yolov5PostProcessInfo_t()
    yolov5_postprocess_info.height = h
    yolov5_postprocess_info.width = w
    org_height, org_width = image.shape[0:2]
    yolov5_postprocess_info.ori_height = org_height
    yolov5_postprocess_info.ori_width = org_width
    yolov5_postprocess_info.score_threshold = 0.4
    yolov5_postprocess_info.nms_threshold = 0.45
    yolov5_postprocess_info.nms_top_k = 50
    yolov5_postprocess_info.is_pad_resize = 0
    
    output_tensors = (hbDNNTensor_t * len(models[0].outputs))()
    for i in range(len(models[0].outputs)):
        output_tensors[i].properties.tensorLayout = get_TensorLayout(outputs[i].properties.layout)
        if len(outputs[i].properties.scale_data) == 0:
            output_tensors[i].properties.quantiType = 0
            output_tensors[i].sysMem[0].virAddr = ctypes.cast(outputs[i].buffer.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), ctypes.c_void_p)
        else:
            output_tensors[i].properties.quantiType = 2
            output_tensors[i].properties.scale.scaleData = outputs[i].properties.scale_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
            output_tensors[i].sysMem[0].virAddr = ctypes.cast(outputs[i].buffer.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)), ctypes.c_void_p)
            
        for j in range(len(outputs[i].properties.shape)):
            output_tensors[i].properties.validShape.dimensionSize[j] = outputs[i].properties.shape[j]
        
        libpostprocess.Yolov5doProcess(output_tensors[i], ctypes.pointer(yolov5_postprocess_info), i)
    
    result_str = get_Postprocess_result(ctypes.pointer(yolov5_postprocess_info))
    result_str = result_str.decode('utf-8')
    
    # Parse JSON - the result is in format '"yolov5_result": [...]'
    # We need to wrap it in braces to make valid JSON
    if result_str.startswith('"yolov5_result"'):
        result_str = '{' + result_str + '}'
        data = json.loads(result_str)
        data = data.get('yolov5_result', [])
    else:
        data = json.loads(result_str)
    
    return data, org_height, org_width


def calculate_bbox_area(bbox):
    """ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®é¢ç©ã‚’è¨ˆç®—ã™ã‚‹"""
    x1, y1, x2, y2 = bbox
    width = max(0, x2 - x1)
    height = max(0, y2 - y1)
    return width * height


def calculate_congestion_rate(image, use_camera=True, image_path=None):
    """
    æ··é›‘ç‡ã‚’è¨ˆç®—ã™ã‚‹
    - personã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®é¢ç©ã‚’è¨ˆç®—
    - ã‚½ãƒ¼ã‚¹ç”»åƒã¨ã®é¢ç©æ¯”ã‚’è¨ˆç®—ã—ã¦æ··é›‘ç‡ã¨ã—ã¦è¿”ã™
    """
    # ç‰©ä½“æ¤œå‡ºã‚’å®Ÿè¡Œ
    detections, img_height, img_width = detect_objects(image)
    
    # ç”»åƒå…¨ä½“ã®é¢ç©
    total_image_area = img_height * img_width
    
    # personã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ã¿ã‚’æŠ½å‡º
    person_detections = [d for d in detections if d['name'] == 'person']
    
    # å„personã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹é¢ç©ã‚’è¨ˆç®—
    person_areas = []
    for person in person_detections:
        bbox = person['bbox']
        area = calculate_bbox_area(bbox)
        person_areas.append({
            'bbox': bbox,
            'area': area,
            'score': person['score'],
            'name': person['name']
        })
    
    # personã®ç·é¢ç©ï¼ˆé‡è¤‡ã‚’è€ƒæ…®ã—ãªã„å˜ç´”åˆè¨ˆï¼‰
    total_person_area = sum(p['area'] for p in person_areas)
    
    # æ··é›‘ç‡ = personã®ç·é¢ç© / ç”»åƒå…¨ä½“ã®é¢ç© * 100
    congestion_rate = (total_person_area / total_image_area) * 100 if total_image_area > 0 else 0
    
    return {
        'congestion_rate': round(congestion_rate, 2),
        'person_count': len(person_detections),
        'total_person_area': total_person_area,
        'total_image_area': total_image_area,
        'image_size': {'width': img_width, 'height': img_height},
        'person_details': person_areas
    }


def load_image_from_file(image_path: str):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(image_path):
        raise Exception(f"Image file not found: {image_path}")
    image = cv2.imread(image_path)
    if image is None:
        raise Exception(f"Failed to load image: {image_path}")
    return image


@app.get("/")
def root():
    """APIã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "æ··é›‘ç‡æ¤œå‡ºAPI",
        "endpoints": {
            "/congestion": "ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’å–å¾—ã—ã¦æ··é›‘ç‡ã‚’è¨ˆç®—",
            "/congestion?image_path=/path/to/image.jpg": "æŒ‡å®šã—ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ··é›‘ç‡ã‚’è¨ˆç®—",
            "/health": "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
        }
    }


@app.get("/health")
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "healthy", "model_loaded": models is not None}


@app.get("/congestion")
def get_congestion(image_path: Optional[str] = None):
    """
    æ··é›‘ç‡ã‚’å–å¾—ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    Parameters:
    - image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯ã‚«ãƒ¡ãƒ©ã‹ã‚‰å–å¾—ï¼‰
    
    Returns:
    - congestion_rate: æ··é›‘ç‡ï¼ˆ%ï¼‰
    - person_count: æ¤œå‡ºã•ã‚ŒãŸäººæ•°
    - total_person_area: personã®ç·é¢ç©ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
    - total_image_area: ç”»åƒå…¨ä½“ã®é¢ç©ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
    - image_size: ç”»åƒã‚µã‚¤ã‚º
    - person_details: å„personã®è©³ç´°æƒ…å ±
    """
    try:
        if image_path:
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            image = load_image_from_file(image_path)
            source = f"file: {image_path}"
        else:
            # ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’å–å¾—
            image = capture_image()
            source = "camera"
        
        # æœ€å¾Œã«ä½¿ç”¨ã—ãŸç”»åƒã‚’ä¿å­˜
        cv2.imwrite(LAST_PHOTO_PATH, image)
        
        result = calculate_congestion_rate(image)
        
        # æ¤œå‡ºçµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(LAST_DETECTION_PATH, 'w') as f:
            json.dump(result, f)
        
        result['source'] = source
        result['last_photo'] = LAST_PHOTO_PATH
        return result
    except Exception as e:
        return {"error": str(e)}


@app.get("/count_people")
def count_people(image_path: Optional[str] = None):
    """äººæ•°ã‚«ã‚¦ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒï¼‰"""
    try:
        if image_path:
            image = load_image_from_file(image_path)
        else:
            image = capture_image()
        
        detections, _, _ = detect_objects(image)
        person_count = sum(1 for d in detections if d['name'] == 'person')
        return {"people_count": person_count}
    except Exception as e:
        return {"error": str(e)}


# ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEST_IMAGES_DIR = os.path.dirname(os.path.abspath(__file__))

# æœ€å¾Œã«æ’®å½±ã—ãŸç”»åƒã®ãƒ‘ã‚¹
LAST_PHOTO_PATH = os.path.join(TEST_IMAGES_DIR, "last_photo.jpg")
# æœ€å¾Œã®æ¤œå‡ºçµæœã‚’ä¿å­˜ã™ã‚‹ãƒ‘ã‚¹
LAST_DETECTION_PATH = os.path.join(TEST_IMAGES_DIR, "last_detection.json")

def get_test_images():
    """ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºï¼ˆè‡ªå‹•ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    exclude_files = {'last_photo', 'last_photo_with_boxes'}  # è‡ªå‹•ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
    images = {}
    for filename in os.listdir(TEST_IMAGES_DIR):
        ext = os.path.splitext(filename)[1].lower()
        name = os.path.splitext(filename)[0]
        if ext in image_extensions and name not in exclude_files:
            images[name] = os.path.join(TEST_IMAGES_DIR, filename)
    return images


@app.get("/test")
def list_test_images():
    """åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆç”»åƒä¸€è¦§ã‚’å–å¾—"""
    test_images = get_test_images()
    available = {}
    for name, path in test_images.items():
        available[name] = {
            "path": path,
            "exists": os.path.exists(path)
        }
    return {
        "message": "ãƒ†ã‚¹ãƒˆç”»åƒä¸€è¦§",
        "images": available,
        "usage": "/test/{image_name} ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆæ‹¡å¼µå­ä»˜ãã§ã‚‚å¯ï¼‰"
    }


@app.get("/test/last_photo", response_class=HTMLResponse)
def get_last_photo_html():
    """
    æœ€å¾Œã«/congestionã§ä½¿ç”¨ã—ãŸç”»åƒã‚’HTMLã§è¡¨ç¤º
    """
    if not os.path.exists(LAST_PHOTO_PATH):
        return HTMLResponse(
            content="<html><body><h1>No photo available</h1><p>Call /congestion first.</p></body></html>",
            status_code=404
        )
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥å›é¿ç”¨ã«è¿½åŠ 
    timestamp = int(os.path.getmtime(LAST_PHOTO_PATH) * 1000)
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Last Photo - æ··é›‘ç‡æ¤œå‡º</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; background: #f0f0f0; }}
            h1 {{ color: #333; }}
            img {{ max-width: 100%; height: auto; border: 2px solid #333; }}
            .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
            .info {{ margin-top: 10px; color: #666; }}
            a {{ color: #0066cc; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ“· Last Photo</h1>
            <img src="/test/last_photo.jpg?t={timestamp}" alt="Last captured photo">
            <div class="info">
                <p>ã“ã®ç”»åƒã¯æœ€å¾Œã« /congestion ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ä½¿ç”¨ã•ã‚ŒãŸç”»åƒã§ã™ã€‚</p>
                <p><a href="/congestion">â†’ /congestion ã‚’å®Ÿè¡Œã—ã¦æ–°ã—ã„ç”»åƒã‚’å–å¾—</a></p>
                <p><a href="/test">â†’ ãƒ†ã‚¹ãƒˆç”»åƒä¸€è¦§ã«æˆ»ã‚‹</a></p>
            </div>
        </div>
    </body>
    </html>
    """
    return HTMLResponse(content=html)


def draw_bounding_boxes(image, detections):
    """ç”»åƒã«ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»ã™ã‚‹"""
    img_with_boxes = image.copy()
    
    for det in detections:
        bbox = det['bbox']
        score = det['score']
        name = det.get('name', 'unknown')
        
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
        x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])
        
        # personã¯ç·‘ã€ãã‚Œä»¥å¤–ã¯é’
        color = (0, 255, 0) if name == 'person' else (255, 0, 0)
        cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
        
        # ãƒ©ãƒ™ãƒ«ã‚’æç”»
        label = f'{name} {score:.2f}'
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        
        # ãƒ©ãƒ™ãƒ«èƒŒæ™¯
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
        cv2.rectangle(img_with_boxes, (x1, y1 - text_height - 10), (x1 + text_width, y1), color, -1)
        cv2.putText(img_with_boxes, label, (x1, y1 - 5), font, font_scale, (255, 255, 255), thickness)
    
    return img_with_boxes


@app.get("/test/last_photo.jpg")
def get_last_photo_image():
    """
    æœ€å¾Œã«/congestionã§ä½¿ç”¨ã—ãŸç”»åƒã«ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»ã—ã¦è¿”ã™
    """
    if not os.path.exists(LAST_PHOTO_PATH):
        return {"error": "No photo available. Call /congestion first."}
    
    # å…ƒç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imread(LAST_PHOTO_PATH)
    
    # æ¤œå‡ºçµæœãŒã‚ã‚Œã°ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
    if os.path.exists(LAST_DETECTION_PATH):
        with open(LAST_DETECTION_PATH, 'r') as f:
            detection_result = json.load(f)
        
        person_details = detection_result.get('person_details', [])
        if person_details:
            image = draw_bounding_boxes(image, person_details)
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦è¿”ã™
    temp_path = os.path.join(TEST_IMAGES_DIR, "last_photo_with_boxes.jpg")
    cv2.imwrite(temp_path, image)
    
    return FileResponse(
        temp_path,
        media_type="image/jpeg",
        filename="last_photo.jpg"
    )


@app.get("/test/{image_name}")
def test_congestion(image_name: str):
    """
    ãƒ†ã‚¹ãƒˆç”»åƒã§æ··é›‘ç‡ã‚’æ¤œè¨¼ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    Parameters:
    - image_name: ãƒ†ã‚¹ãƒˆç”»åƒåï¼ˆæ‹¡å¼µå­ä»˜ãã§ã‚‚å¯ï¼‰
    
    Returns:
    - æ··é›‘ç‡æ¤œå‡ºçµæœ + æ¤œè¨¼æƒ…å ±
    """
    # æ‹¡å¼µå­ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–
    normalized_name = os.path.splitext(image_name)[0]
    
    # å‹•çš„ã«ãƒ†ã‚¹ãƒˆç”»åƒã‚’å–å¾—
    test_images = get_test_images()
    
    if normalized_name not in test_images:
        return {
            "error": f"Unknown test image: {image_name}",
            "available_images": list(test_images.keys())
        }
    
    image_path = test_images[normalized_name]
    
    if not os.path.exists(image_path):
        return {"error": f"Test image not found: {image_path}"}
    
    try:
        image = load_image_from_file(image_path)
        
        # æœ€å¾Œã«ä½¿ç”¨ã—ãŸç”»åƒã‚’ä¿å­˜
        cv2.imwrite(LAST_PHOTO_PATH, image)
        
        result = calculate_congestion_rate(image)
        
        # æ¤œå‡ºçµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(LAST_DETECTION_PATH, 'w') as f:
            json.dump(result, f)
        
        # ãƒ†ã‚¹ãƒˆæ¤œè¨¼æƒ…å ±ã‚’è¿½åŠ 
        result['test_info'] = {
            'image_name': normalized_name,
            'image_path': image_path,
            'verification': {
                'is_crowded': result['congestion_rate'] > 10,  # 10%ä»¥ä¸Šã§æ··é›‘
                'crowd_level': get_crowd_level(result['congestion_rate'])
            }
        }
        return result
    except Exception as e:
        return {"error": str(e)}


def get_crowd_level(rate: float) -> str:
    """æ··é›‘ç‡ã‹ã‚‰æ··é›‘ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š"""
    if rate < 5:
        return "ç©ºã„ã¦ã„ã‚‹"
    elif rate < 15:
        return "ã‚„ã‚„æ··é›‘"
    elif rate < 30:
        return "æ··é›‘"
    else:
        return "éå¸¸ã«æ··é›‘"


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)